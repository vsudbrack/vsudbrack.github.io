<!DOCTYPE html>
<html class="">
<head>
  <meta charset="UTF-8">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta rel="author" href="">
  <meta rel="publisher" href="">
  <meta property="og:image" content="https://raw.githubusercontent.com/vsudbrack/vsudbrack.github.io/master/assets/img/general/banner_square.png">

  <title>
    
      Methods of numerical integration for ODEs | Vitor Sudbrack
    
  </title>

  <link rel="stylesheet" href="/assets/css/all.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
  <!--[if lt IE 9]><script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <!-- Use Atom -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Vitor Sudbrack" />

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <!-- Math equations -->
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    }
  });
  </script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  <!-- Use Jekyll SEO plugin -->
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Methods of numerical integration for ODEs | Vitor Sudbrack</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Methods of numerical integration for ODEs" />
<meta name="author" content="Vitor Sudbrack" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Summary and diagrams for numerical integration of ODE and systems of ODEs." />
<meta property="og:description" content="Summary and diagrams for numerical integration of ODE and systems of ODEs." />
<link rel="canonical" href="http://localhost:4000/odes" />
<meta property="og:url" content="http://localhost:4000/odes" />
<meta property="og:site_name" content="Vitor Sudbrack" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-01-03T02:00:21+01:00" />
<script type="application/ld+json">
{"description":"Summary and diagrams for numerical integration of ODE and systems of ODEs.","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/odes"},"author":{"@type":"Person","name":"Vitor Sudbrack"},"@type":"BlogPosting","url":"http://localhost:4000/odes","dateModified":"2021-01-03T02:00:21+01:00","datePublished":"2021-01-03T02:00:21+01:00","headline":"Methods of numerical integration for ODEs","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


</head>
<body>

<div class="site-container">

  <header>
  <div class="logo">
    <a href="/">Vitor Sudbrack</a>
  </div>
  <nav>
    
      <a href="/about">About</a>
    
      <a href="/courses.html">Courses</a>
    
      <a href="/codes.html">Codes</a>
    
      <a href="/contact">Contact</a>
    
  </nav>
</header>


  <section>

  <div class="work-container">


    <h1 class="project-title">Methods of numerical integration for ODEs</h1>

	<br>
	<div class="project-load"><p>This is a <strong>summary of different methods for numerical integration</strong>. It is supposed to be brief and sucint, pointing to the most important points. I wrote its first version in 2016 when I was tutor of the course for <em>Computational methods for physics - B</em> at the <em>Institute of Physics</em> of <em>Univerisidade Federal do Rio Grande do Sul</em>, to help students to prepare themselves for the final exam.</p>

<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a>    <ul>
      <li><a href="#system-of-odes" id="markdown-toc-system-of-odes">System of ODEs</a></li>
      <li><a href="#local-and-global-errors" id="markdown-toc-local-and-global-errors">Local and global errors</a></li>
    </ul>
  </li>
  <li><a href="#eulerian-methods" id="markdown-toc-eulerian-methods">Eulerian methods</a>    <ul>
      <li><a href="#explicit--implicit-euler-method" id="markdown-toc-explicit--implicit-euler-method">Explicit &amp; Implicit Euler method</a></li>
      <li><a href="#euler-cromer-method" id="markdown-toc-euler-cromer-method">Euler-Cromer method</a></li>
      <li><a href="#verlet--velocity-verlet-methods" id="markdown-toc-verlet--velocity-verlet-methods">Verlet &amp; Velocity-Verlet methods</a></li>
    </ul>
  </li>
  <li><a href="#runge-kutta-methods" id="markdown-toc-runge-kutta-methods">Runge-Kutta methods</a></li>
  <li><a href="#multistep-methods-adams-bashforth--adams-moulton" id="markdown-toc-multistep-methods-adams-bashforth--adams-moulton">Multistep methods: Adams-Bashforth &amp; Adams-Moulton</a></li>
  <li><a href="#predictorcorrector-method" id="markdown-toc-predictorcorrector-method">Predictor–Corrector method</a></li>
  <li><a href="#variable-step-size-methods" id="markdown-toc-variable-step-size-methods">Variable step-size methods</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>Here we’ll focus on elementary examples from physics, and therefore consider $2^{nd}$ order ordinary differential equations (ODEs) - such as <em>Newton’s second law</em> - and name functions of time ($t$) as position ($x(t)$) and velocity/speed ($v(t)$). Naturally, the applications of these methods are much more general than mechanical systems.</p>

<p>Also, we will focous on <em>initial value problems</em>. Hence, to solve a differential equation of order N numerically, it will be <strong>necessary to know the value of the function and its $N-1$ first derivatives in an initial instant</strong>, the <em>initial condition</em> of the problem. To solve such examples, it is usually employed finite element methods as the ones we summarize here. The standard notation of this discretization is</p>

\[t_n = n\Delta t \\
x_n = x(t_n) \\
v_n = v(t_n)\]

<p>Keep in mind though, that in different kinds of problems involving ODEs, the ones with boundary conditions for instance, other families of methods may be more adequate, such as spectral methods.</p>

<h4 id="system-of-odes">System of ODEs</h4>

<p>It is important to know that <strong>any differential equation of order N can be rewritten as a system of N first order ODEs</strong>, through the definition of new functions - the derivatives. Hence, methods that solve $1^{st}$ order ODEs can be applied $N$ times in a row to solve any order ODE. For instance Newton’s law</p>

\[\frac{d^2x}{dt^2} = a(v,x,t)\]

<p>can be rewritten as the system of two coupled equations, $\frac{dx}{dt} = v(x,t)$ and $\frac{dv}{dt} = a(v,x,t)$ by simply renaming the first derivative of $x$ as $v$.</p>

<h4 id="local-and-global-errors">Local and global errors</h4>

<p>It is fundamental to keep in mind that numerical solutions are always <strong>approximations</strong> to the real solutions, including (at least) two errors: <strong>truncation errors</strong> and <strong>round-off errors</strong>.</p>

<p>Round-off errors are due to the <strong>precision of the machine</strong>. Currently, computers are extremely precise, operating with 8 or 16 significant digits (float and double, respectively). Although summing a large number to a small number can cause reductions on the precision of result.</p>

<p>Now, the real-deal, it is the truncation errors due to the <strong>finite mathematical terms used to represent a limiting operation</strong>, such as derivatives. Typically, we’ll be truncating the Taylor expansion for small time-steps, and therefore <strong>these errors scale as power-laws of $\Delta t$.</strong></p>

<p>Ignoring the round-off errors in face of the truncation errors, we call the last as the <strong>local error</strong> between time-steps. The error in the approximation of numerical solution is the accumulation oflocal errors on several time-steps, hence <strong>global error</strong>, depending on the local error and on the length integration interval, $t_f-t_0$.</p>

<h2 id="eulerian-methods">Eulerian methods</h2>

<h4 id="explicit--implicit-euler-method">Explicit &amp; Implicit Euler method</h4>

<p>The <strong>Explicit Euler method</strong> is the most elementary idea - substitute the limiting derivatives by very small finite steps.</p>

\[x_{n+1} = x_n+v(x_n,t_n)\Delta t\]

<p>It solves $1^{st}$ order ODEs with a local error of order $\Delta t^2$. It is usually not recommended due to problems on stability, especially considering mechanical problems in which energy is conserved.</p>

<p>When the equation of $v(x,t)$ is linear on $x$, we can write an improvement called <strong>Implicit Euler method</strong> by solving</p>

\[x_{n+1} = x_n+v(x_{n+1},t_n)\Delta t\]

<p>for $x_{n+1}$. It increases the stability of Euler method drastically, altough it is rarely feasible.</p>

<h4 id="euler-cromer-method">Euler-Cromer method</h4>

<p>When it comes to $2^{nd}$ order ODE, then we can use Euler methods repeatedly from the highest derivative to the lowest one, employing the most recent updates forward. The <strong>Euler-Cromer method</strong> goes as follows</p>

\[{\bf v_{n+1}} = v_n+a(x_n,t_n)\Delta t \\
x_{n+1} = x_n+{\bf v_{n+1}}\Delta t\]

<p>Again, the local error is of order $\Delta t^2$, but this method is generally more stable than the previous <em>Explicit Euler method</em>.</p>

<h4 id="verlet--velocity-verlet-methods">Verlet &amp; Velocity-Verlet methods</h4>

<p>If we Taylor-expand $x(t+\Delta t)$ and $x(t-\Delta t)$, we observe that we can conveniently sum both expansions to cancel all odd derivatives, especially the first! Hence, the so-called <strong>Verlet method</strong> allows us to integrate a $2^{nd}$ order ODE without the need of calculating its first derivative and local error of order $\Delta t^4$!</p>

<p>The recipe is</p>

\[x_ {n+1} = 2x_n - x_{n-1} + a(x_n,t_n)\Delta t^2\]

<p>Although we have one less variable in the equation above ($v$ is gone!), we need to store $x$ on the previous instant $n-1$ as well as the current ($n$). And also the first integration has to be done outside the main loop, with $x_1=x_0-v_0\Delta t$.</p>

<p>If wanted, you can estimate the velocity at any instant afterwards through midpoint derivative, $v_n = \frac{x_ {n+1}-x_{n-1}}{2\Delta t}$.</p>

<p>But in order to better estimate the velocity, we can add it back into the numerical integration, in the <strong>Velocity-Verlet method</strong>. We improve the local error on velocity updating it twice, first to the midpoint ($v_{n+1/2}$) and then to the end of the time step.</p>

\[{\bf v_{n+1/2}} = v_n+a(x_n,t_n)\Delta t/2 \\
x_{n+1} = x_n+{\bf v_{n+1/2}}\Delta t \\
v_{n+1} = {\bf v_{n+1/2}}+a(x_{n+1},t_n)\Delta t/2\]

<p>Here, the local error on $x$ is still order $\Delta t^4$ as Verlet, but the error in $v$ is improved to order $\Delta t^3$.</p>

<p>Also, it is very important to notice that <strong>we cannot apply neither Verlet nor Velocity-Verlet methods on velocity-dependent forces</strong>, such as friction for instance ($a$ is <em>not</em> a function of $v$), because it destabilizes these numerical methods.</p>

<h2 id="runge-kutta-methods">Runge-Kutta methods</h2>

<p>In the last method, we introduced $v_{n+1/2}$ - one <em>partial update</em>. In <strong>Runge-Kutta (RK) methods</strong>, which is actually a family of several similar methods, we further explore the same idea of considering multiple midpoints in the interval $[t, t+\Delta t]$ and combining the information at these midpoints conveniently.</p>

<p>We will be interested in the derivatives (slopes) at these midpoints, and we denote them by $k_i$. The final estimate of the derivative is a <strong>weighted average</strong> between the collection of $k_i$’s. The different methods choose different sampling points and different weights - and there is a whole mechanism on how to generate new RK methods, called <strong><a href="https://en.wikipedia.org/wiki/Butcher_tableau">Butcher tableau</a></strong>. In fact, the previous Eulerian methods were also the most basic RK methods with one sampling point.</p>

<p>The most used ones are in this diagram.</p>

<div class="image-container">
<a href="/assets/img/blog/rungekutta.svg" target="_blank">
    <img src="/assets/img//blog/rungekutta.svg" alt="Avatar" class="image" />
    <div class="overlay">
      <div class="text" style="color:">
        Diagram for equations of Runge-Kutta methods (click to maximize)
	 <i class="fa fa-arrow-right" aria-hidden="true" style="color:"></i>
      </div>
    </div>

</a>

</div>

<p>The most famous are <strong>RK23</strong> (2 slopes to produce a local error of order $\Delta t^3$) and <strong>RK45</strong> (4 slopes to produce a local error of order $\Delta t^5$). Notice that when considering more than $5$ slopes, the local error exponent does not increase linearly - for that reason, the <em>RK45</em> is typically the best choice for numerical integrations.</p>

<h2 id="multistep-methods-adams-bashforth--adams-moulton">Multistep methods: Adams-Bashforth &amp; Adams-Moulton</h2>

<p>We can use information about points previously calculated to improve the estimation of the next point. The explicit method (which uses only dots earlier) is called <strong>Adams-Bashforth (AB) method</strong> and the implicit method (which uses the point itself) is called <strong>Adams-Moulton (AM) method</strong>.</p>

<p>In both implicit and explicit methods, there are different orders $m$, which is the number of previous points employed.</p>

<div class="image-container">
<a href="/assets/img/blog/multistep.svg" target="_blank">
    <img src="/assets/img//blog/multistep.svg" alt="Avatar" class="image" />
    <div class="overlay">
      <div class="text" style="color:">
        Diagram for equations of Multistep methods (click to maximize)
	 <i class="fa fa-arrow-right" aria-hidden="true" style="color:"></i>
      </div>
    </div>

</a>

</div>

<p>Local errors scale as $\Delta t^m$ with AB and $\Delta t^{m+1}$ with AM - another example of the general principal that implicit methods are more accurate.</p>

<h2 id="predictorcorrector-method">Predictor–Corrector method</h2>

<p>Because to use the AM method it is necessary to know the slope at point $x_{n+1}$ to calculate it. As we still don’t know $x_{n+1}$, we predict it with the AB method and then we correct its value with the AM method, and hence the name <strong>Predictor–Corrector method</strong>.</p>

<p>Predict the next point $n+1$ explicitly with</p>

\[x^{pred}_{n+1} = AB(x_n, x_{n-1},...,x_{n-m})\]

<p>and afterwards correct it implicitly with</p>

\[x_{n+1} = AM(x^{pred}_{n+1}, x_n, x_{n-1},...,x_{n-m})\]

<p>When implementing it computationally, pay attention when updating the values on the correct positions - it must be done in reversed order! From the oldest to the most recent:</p>

\[x_{n-m} = x_{n-m+1} \\ 
x_{n-m+1} = x_{n-m+2} \\ 
... \\
x_{n-1} = x_{n} \\ 
x_{n} = x_{n+1} \\\]

<h2 id="variable-step-size-methods">Variable step-size methods</h2>

<p>If slopes in functions aren’t uniform during the integrating range, why should we take constant time step-sizes? The <strong>time step-size should adapt across the interval of integration</strong>.</p>

<p>Hence, variable-step methods is an optimization which allows you to adapt the step size ($\Delta t$) to be as large as possible (consuming therefore less execution time) while controlling the function error. Intuitively, at the points where functions have sharp slopes the $\Delta t$ will be minimal and when functions have smooth derivatives, $\Delta t$ will be larger.</p>

<p>If we updated the time step at every iteration, we’d end up adding a new calculation as costly as the integration, increasing the execution time. Therefore, we must <strong>update $\Delta t$ every block of $N$ iterations</strong>. If we have previously an estimation of the average time-step on the interval of integration $(t_0, t_f)$, we can make a polite guess for N:</p>

\[N \approx \sqrt{\frac{t_f-t_0}{\Delta t_{AVG}}}\]

<p>i.e., we are balancing $N$ blocks of $N$ iterations.</p>

<p>This is <em>not</em> a new method itself, but an optimization for the previous methods, as it reduces the execution time while still controlling the size of the error. You can <strong>implement variable time step-size in any of the previous method</strong>, and it is important to know the order of local errors $m$.</p>

<p>We also need to define an <strong>arbitrarily tolerable error</strong> ($\epsilon$), communly $10^{-6}$. Notice that much smaller tolerable errors are also subjected to <strong>round-off errors</strong>, i.e., errors due to the machine precision, that are independent of integrating method.</p>

<p>The update follows</p>

\[\Delta t_{new} = \Delta t \left(\frac{\epsilon}{\epsilon_C}\right)^{1/m}\]

<p>where $\epsilon_C$ is the <strong>current error estimator</strong> - and here is the key issue: <em>how to estimate the current error without increasing the number of calculations?</em> Typically one can use the fact that some of the methods are nested, for instance RK45 has inside it RK23 of double step-size. In this example, we could integrate the functions with RK45 and estimate the current error comparing RK45 with RK23.</p>

<p>The last note is to <strong>avoid abrupt changes in $\Delta t$</strong> for the stability of the original method and better prediction of the current error. For that, estimate $\Delta t_{new}$ as mentioned and add a <em>if-else</em> statement where increments $&gt;500\%$ or reductions $&gt;-80\%$ are replaced for $5\Delta t$ or $\Delta t/5$, respect.</p>

<hr />

<p>My gratitude to Prof. Heitor Carpes Marques Fernandes, from <em>IF-UFRGS</em>, who was responsible for the course I was tutoring and helped me polish this summary in its first versions.</p>

</div>
  </div>

<button id='scroll-to-top'><svg viewBox="0 0 24 24"><path d="M4 12l1.41 1.41L11 7.83V20h2V7.83l5.58 5.59L20 12l-8-8-8 8z"/></svg></button>

</section>



<script src="/assets/js/toc.js"></script>

<script type="text/javascript">
$(document).ready(function() {
    $('#toc').toc({});
});
</script>


 

  <footer>
	
  <div class="footer-wrap">
    <div class="footer-tagline">
      <p></p>
    </div>
    <div class="social-media">
      <nav>
        
          <a href="https://twitter.com/vitorsudbrack" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
        
          <a href="https://www.facebook.com/vsudbrack" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
        
          <a href="https://www.instagram.com/v_sud/" target="_blank"><i class="fa fa-instagram" aria-hidden="true"></i></a>
        
          <a href="https://www.youtube.com/channel/UCNRrtOK8RIkds4VUFm04Ptw" target="_blank"><i class="fa fa-youtube" aria-hidden="true"></i></a>
        
          <a href="https://github.com/vsudbrack" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
        
          <a href="mailto:vitorsudbrack@gmail.com" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
        
      </nav>
    </div>
	
  </div>
<p style="text-align:center;font-size:10px;margin-bottom:2px">Contents © 2020 <a href="mailto:vitorsudbrack@gmail.com">Vitor Sudbrack</a>.</p>
<p style="text-align:center;font-size:10px"><a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License BY-NC-SA" style="border-width:0; margin-bottom:2px;" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"></a></p>
</footer>


</div>

  <!-- Default Statcounter code for Vsudbrack Homepage
https://vsudbrack.github.io/ -->
<script type="text/javascript">
var sc_project=12383098; 
var sc_invisible=1; 
var sc_security="f546f377"; 
var sc_https=1; 
</script><script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js" async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img class="statcounter"
src="https://c.statcounter.com/12383098/0/f546f377/1/" alt="Web
Analytics"></a></div></noscript>
<!-- End of Statcounter Code -->



<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
<script src="/assets/js/functions.js"></script>

</body>
</html>
